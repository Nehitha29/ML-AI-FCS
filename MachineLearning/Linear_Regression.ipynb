{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a58057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31efd6",
   "metadata": {},
   "source": [
    "###  1. Generate two datasets, X (training set) and X1 (test set), each consisting of N = 1000 3-dimensional vectors that stem from three classes, ω1, ω2, and ω3, with prior-probabilities P(ω1)=P(ω2)=P(ω3)=1/3. The classes are modeled by Gaussian distributions with means m1 = [0, 0, 0]T , m2 = [1, 2, 2]T , and m3 = [3, 3, 4]T respectively; their covariance matrices are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Use the Euclidean distance classifier to classify the points of X1.\n",
    "# (b) Use the Mahalanobis distance classifier to classify the points of X1.\n",
    "# (c) Use the Bayesian classifier to classify the points of X1.\n",
    "# (d) For each class, compute the error probability and compare the results.\n",
    "# (e) Experiment with the mean values (bringing them closer or taking them farther away)\n",
    "# and the a prior-probabilities. Comment on the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8ff203",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.array([0, 0, 0])\n",
    "m2 = np.array([1, 2, 2])\n",
    "m3 = np.array([3, 3, 4])\n",
    "\n",
    "\n",
    "S1 = np.array([[0.8,0.2,0.1],\n",
    "              [0.2,0.8,0.2],\n",
    "              [0.1,0.2,0.8]])\n",
    "\n",
    "S2 = np.array([[0.6,0.01,0.01],\n",
    "              [0.01,0.8,0.01],\n",
    "              [0.01,0.01,0.6]])\n",
    "\n",
    "S3 = np.array([[0.6,0.1,0.1],\n",
    "              [0.1,0.6,0.1],\n",
    "              [0.1,0.1,0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df448715",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "prior_probs = [1/3, 1/3, 1/3]\n",
    "\n",
    "X = np.vstack([\n",
    "    np.random.multivariate_normal(m1,S1,N),\n",
    "    np.random.multivariate_normal(m2,S2,N),\n",
    "    np.random.multivariate_normal(m3,S3,N)\n",
    "])\n",
    "\n",
    "X1 = np.vstack([\n",
    "    np.random.multivariate_normal(m1,S1,N),\n",
    "    np.random.multivariate_normal(m2,S2,N),\n",
    "    np.random.multivariate_normal(m3,S3,N)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "964f7567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    return np.linalg.norm(x - y)\n",
    "def euclidean_classifier(x, means):\n",
    "    distances = [euclidean_distance(x, m) for m in means]\n",
    "    return np.argmin(distances)\n",
    "means = [m1, m2, m3]\n",
    "predicted_euclidean = [euclidean_classifier(test, means) for test in X1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a5d0a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Classifier    0.059333333333333335\n"
     ]
    }
   ],
   "source": [
    "actual_labels = np.repeat(np.arange(3), N)\n",
    "euclidean_error = np.mean(predicted_euclidean != actual_labels)\n",
    "print(\"Euclidean Classifier   \", euclidean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f2fa679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Bayesian classifier to classify the points of X1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ff5fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_pdf(x, mean, cov):\n",
    "    d = len(x)\n",
    "    coefficient = 1 / (np.sqrt((2 * np.pi)**d * np.linalg.det(cov)))\n",
    "    exponent = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x-mean))\n",
    "    return coefficient * np.exp(exponent)\n",
    "\n",
    "def bayesian_classifier(point, means, covariances, priors):\n",
    "    likelihoods = [multivariate_normal_pdf(point, mean, cov) for mean, cov in zip(means, covariances)]\n",
    "    posterior_probs = [likelihood * prior for likelihood, prior in zip(likelihoods, prior_probs)]\n",
    "    return np.argmax(posterior_probs)\n",
    "\n",
    "predicted_bayesian = [bayesian_classifier(test, [m1, m2, m3], [S1, S2, S3], prior_probs) for test in X1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26c0b424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian classifier    0.05733333333333333\n"
     ]
    }
   ],
   "source": [
    "actual_labels = np.repeat(np.arange(3), N)\n",
    "predicted_bayesian_error = np.mean( predicted_bayesian!= actual_labels)\n",
    "print(\"Bayesian classifier   \",predicted_bayesian_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19be3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(b) Use the Mahalanobis distance classifier to classify the points of X1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ffafcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(x, mean, cov):\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    diff = x - mean\n",
    "    mahalano = np.sqrt(np.dot(np.dot(diff.T, inv_cov), diff))\n",
    "    return mahalano\n",
    "\n",
    "def mahalanobis_classifier(x, means, covs):\n",
    "    distances = [mahalanobis_distance(x, mean, cov) for mean, cov in zip(means, covariances)]\n",
    "    return np.argmin(distances)\n",
    "covariances = [S1, S2, S3]\n",
    "\n",
    "predicted_mahalanobis = [mahalanobis_classifier(test,[m1, m2, m3], [S1, S2, S3]) for test in X1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71ab2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahalanobis distance   0.059\n"
     ]
    }
   ],
   "source": [
    "actual_labels = np.repeat(np.arange(3), N)\n",
    "predicted_mahalanobis_error = np.mean( predicted_mahalanobis!= actual_labels)\n",
    "print(\"Mahalanobis distance  \",predicted_mahalanobis_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e2387",
   "metadata": {},
   "outputs": [],
   "source": [
    " #For each class, compute the error probability and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "212b58c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mahalanobis distance  0.059\n",
      "Bayesian classifier   0.05733333333333333\n",
      "Euclidean Classifier    0.059333333333333335\n"
     ]
    }
   ],
   "source": [
    "print(\"Mahalanobis distance \",predicted_mahalanobis_error)\n",
    "print(\"Bayesian classifier  \",predicted_bayesian_error)\n",
    "print(\"Euclidean Classifier   \", euclidean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with the mean values (bringing them closer or taking them farther away) and the a prior-probabilities. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f74d6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = np.array([1, 1, 1])\n",
    "m2 = np.array([6, 6, 2])\n",
    "m3 = np.array([6, 6, 4])\n",
    "\n",
    "\n",
    "S11 = np.array([[0.8,0.2,0.1],\n",
    "              [0.2,0.8,0.2],\n",
    "              [0.1,0.2,0.8]])\n",
    "\n",
    "S12 = np.array([[0.6,0.01,0.01],\n",
    "              [0.01,0.8,0.01],\n",
    "              [0.01,0.01,0.6]])\n",
    "\n",
    "S13 = np.array([[0.6,0.1,0.1],\n",
    "              [0.1,0.6,0.1],\n",
    "              [0.1,0.1,0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40ea9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "prior_probs = [1/3, 1/3, 1/3]\n",
    "\n",
    "X_new = np.vstack([\n",
    "    np.random.multivariate_normal(m1,S1,N),\n",
    "    np.random.multivariate_normal(m2,S2,N),\n",
    "    np.random.multivariate_normal(m3,S3,N)\n",
    "])\n",
    "\n",
    "X1_new = np.vstack([\n",
    "    np.random.multivariate_normal(m1,S1,N),\n",
    "    np.random.multivariate_normal(m2,S2,N),\n",
    "    np.random.multivariate_normal(m3,S3,N)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8ce5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted_bayesian = [bayesian_classifier(test, [m1, m2, m3], [S1, S2, S3], prior_probs) for test in X1_new]\n",
    "predicted_mahalanobis = [mahalanobis_classifier(test,[m1, m2, m3], [S1, S2, S3]) for test in X1_new]\n",
    "predicted_euclidean = [euclidean_classifier(test, means) for test in X1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15d92c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Occured due to the, \n",
      "Euclidean Classifier is:    0.5143333333333333\n",
      "Mahalanobis Classifier is:  0.06533333333333333\n",
      "Bayesian Classifier is:     0.065\n"
     ]
    }
   ],
   "source": [
    "actual_labels = np.repeat(np.arange(3), N)\n",
    "\n",
    "euclidean_error = np.mean(predicted_euclidean != actual_labels)\n",
    "\n",
    "mahalanobis_error = np.mean(predicted_mahalanobis != actual_labels)\n",
    "\n",
    "bayesian_error = np.mean(predicted_bayesian != actual_labels)\n",
    "\n",
    "print(\"Error Occured due to the, \")\n",
    "print(\"Euclidean Classifier is:   \", euclidean_error)\n",
    "print(\"Mahalanobis Classifier is: \", mahalanobis_error)\n",
    "print(\"Bayesian Classifier is:    \", bayesian_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98783dac",
   "metadata": {},
   "source": [
    "### Considering the California Housing dataset, design a linear regression model considering each feature with non zero values, and report the best feature and model accordng to the R2 metric. (Evaluate your linear regression model using sum of squares due to regression (SSR), sum of squares error (SSE), sum of squares total (SST) and coefficient of determination R2 metric and adjusted R2 metric.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f29c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "caldata = datasets.fetch_california_housing()\n",
    "X = caldata.data\n",
    "y = caldata.target\n",
    "feature_names = caldata.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4cde1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (20640, 8)\n",
      "Target shape: (20640,)\n",
      "Feature names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Feature names:\", feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8755f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "\n",
    "    X_single_feature = X[:, [i]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_single_feature, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    y_mean = np.mean(y_test)\n",
    "    SST = np.sum((y_test - y_mean) ** 2)\n",
    "    SSR = np.sum((y_pred - y_mean) ** 2)\n",
    "    SSE = np.sum((y_test - y_pred) ** 2)\n",
    "\n",
    "    R2 = SSR / SST\n",
    "    n = len(y_test)\n",
    "    p = 1  \n",
    "    adjusted_R2 = 1 - (1 - R2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "    results[feature_name] = {\n",
    "        'R2': R2,\n",
    "        'Adjusted R2': adjusted_R2,\n",
    "        'SST': SST,\n",
    "        'SSR': SSR,\n",
    "        'SSE': SSE\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e0e0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  R2  Adjusted R2          SST          SSR          SSE\n",
      "MedInc      0.474947     0.474820  5409.368262  2569.163353  2927.229928\n",
      "HouseAge    0.011083     0.010843  5409.368262    59.949346  5341.474007\n",
      "AveRooms    0.035268     0.035034  5409.368262   190.776231  5334.744201\n",
      "AveBedrms   0.005555     0.005314  5409.368262    30.049652  5411.343822\n",
      "Population  0.000886     0.000644  5409.368262     4.792260  5408.865012\n",
      "AveOccup    0.000238    -0.000004  5409.368262     1.287342  5406.214294\n",
      "Latitude    0.021122     0.020885  5409.368262   114.258037  5290.818102\n",
      "Longitude   0.002344     0.002103  5409.368262    12.681961  5399.860942\n",
      "\n",
      "Best Feature: MedInc\n",
      "R^2: 0.4749470231159636\n",
      "Adjusted R^2: 0.47481976839543905\n",
      "SST: 5409.368262178434\n",
      "SSR: 2569.1633530596205\n",
      "SSE: 2927.229928184818\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "best_feature = results_df['R2'].idxmax()\n",
    "best_results = results_df.loc[best_feature]\n",
    "\n",
    "print(\"\\nBest Feature:\", best_feature)\n",
    "print(\"R^2:\", best_results['R2'])\n",
    "print(\"Adjusted R^2:\", best_results['Adjusted R2'])\n",
    "print(\"SST:\", best_results['SST'])\n",
    "print(\"SSR:\", best_results['SSR'])\n",
    "print(\"SSE:\", best_results['SSE'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
